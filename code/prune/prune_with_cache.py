from surrogate import train
from utils import get_args
from influence_score import get_influence_score
from effort_score import get_effort_score

import torch
import math
import random
import os

if __name__ == '__main__':
    # åŠ è½½å‚æ•°
    args = get_args()
    
    # åˆ›å»ºç¼“å­˜ç›®å½•
    cache_dir = f"/root/autodl-tmp/nku/DEALRec-main/cache/{args.data_name}"
    os.makedirs(cache_dir, exist_ok=True)
    
    # ç¼“å­˜æ–‡ä»¶è·¯å¾„
    influence_cache = f"{cache_dir}/influence_scores.pt"
    effort_cache = f"{cache_dir}/effort_scores.pt"
    trainer_cache = f"{cache_dir}/trainer.pt"
    
    # å·²è®­ç»ƒæ¨¡å‹è·¯å¾„
    existing_model_path = f"/root/autodl-tmp/nku/DEALRec-main/code/prune/models/{args.data_name}.pth"

    print("=== DEALRec æ•°æ®è£å‰ª (åŠ è½½å·²è®­ç»ƒæ¨¡å‹) ===")
    print(f"æ•°æ®é›†: {args.data_name}")
    print(f"æ¨¡å‹è·¯å¾„: {existing_model_path}")
    
    # 1. æ£€æŸ¥å¹¶åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹
    if os.path.exists(trainer_cache):
        print(f"âœ“ ä»ç¼“å­˜åŠ è½½trainer: {trainer_cache}")
        trainer = torch.load(trainer_cache)
    elif os.path.exists(existing_model_path):
        print(f"âœ“ å‘ç°å·²è®­ç»ƒæ¨¡å‹: {existing_model_path}")
        print("ğŸ”„ æ„å»ºtrainerå¹¶åŠ è½½æ¨¡å‹...")
        
        # è®¾ç½®do_eval=Trueæ¥è·³è¿‡è®­ç»ƒï¼Œç›´æ¥åŠ è½½æ¨¡å‹
        args.do_eval = True
        trainer = train(args)  # è¿™ä¼šç›´æ¥åŠ è½½existing_model_path
        
        # ä¿å­˜traineråˆ°ç¼“å­˜
        torch.save(trainer, trainer_cache)
        print(f"âœ“ ä¿å­˜traineråˆ°ç¼“å­˜: {trainer_cache}")
    else:
        print(f"âŒ æœªæ‰¾åˆ°å·²è®­ç»ƒæ¨¡å‹: {existing_model_path}")
        print("ğŸ”„ å¼€å§‹è®­ç»ƒæ–°æ¨¡å‹...")
        args.do_eval = False
        trainer = train(args)
        torch.save(trainer, trainer_cache)
        print(f"âœ“ è®­ç»ƒå®Œæˆå¹¶ä¿å­˜åˆ°ç¼“å­˜: {trainer_cache}")
    
    # 2. è®¡ç®—æˆ–åŠ è½½å½±å“åŠ›å¾—åˆ†
    if os.path.exists(influence_cache):
        print(f"âœ“ ä»ç¼“å­˜åŠ è½½å½±å“åŠ›å¾—åˆ†: {influence_cache}")
        influence = torch.load(influence_cache)
    else:
        print("ğŸ”„ è®¡ç®—å½±å“åŠ›å¾—åˆ†...")
        influence = get_influence_score(args, trainer)
        torch.save(influence, influence_cache)
        print(f"âœ“ ä¿å­˜å½±å“åŠ›å¾—åˆ†åˆ°: {influence_cache}")
    
    # 3. è®¡ç®—æˆ–åŠ è½½åŠªåŠ›å¾—åˆ†
    if os.path.exists(effort_cache):
        print(f"âœ“ ä»ç¼“å­˜åŠ è½½åŠªåŠ›å¾—åˆ†: {effort_cache}")
        effort = torch.load(effort_cache)
    else:
        print("ğŸ”„ è®¡ç®—åŠªåŠ›å¾—åˆ†...")
        effort = get_effort_score(args)
        torch.save(effort, effort_cache)
        print(f"âœ“ ä¿å­˜åŠªåŠ›å¾—åˆ†åˆ°: {effort_cache}")
    
    print(f"\nğŸ“Š å¾—åˆ†ç»Ÿè®¡:")
    print(f"   å½±å“åŠ›å¾—åˆ†: min={torch.min(influence):.4f}, max={torch.max(influence):.4f}")
    print(f"   åŠªåŠ›å¾—åˆ†: min={torch.min(effort):.4f}, max={torch.max(effort):.4f}")
    
    # 4. å½’ä¸€åŒ–
    print("ğŸ”„ å½’ä¸€åŒ–å¾—åˆ†...")
    influence_norm = (influence-torch.min(influence))/(torch.max(influence)-torch.min(influence))
    effort_norm = (effort-torch.min(effort))/(torch.max(effort)-torch.min(effort))

    # 5. è®¡ç®—æ€»ä½“å¾—åˆ†
    print(f"ğŸ”„ è®¡ç®—æ€»ä½“å¾—åˆ† (lambda={args.lamda})...")
    overall = influence_norm + args.lamda * effort_norm
    scores_sorted, indices = torch.sort(overall, descending=True)

    # 6. ç¡¬å‰ªæ
    n_prune = math.floor(args.hard_prune * len(scores_sorted))
    scores_sorted = scores_sorted[n_prune:]
    indices = indices[n_prune:]
    print(f"âœ‚ï¸ ç¡¬å‰ªæåå‰©ä½™æ ·æœ¬: {len(scores_sorted)} (å‰ªæ{args.hard_prune*100}%)")

    # 7. å°†å¾—åˆ†åˆ†æˆkä¸ªèŒƒå›´
    s_max = torch.max(scores_sorted)
    s_min = torch.min(scores_sorted)
    print(f"ğŸ“ˆ å¾—åˆ†èŒƒå›´: {s_min:.4f} ~ {s_max:.4f}")
    interval = (s_max - s_min) / args.k

    s_split = [min(s_min + (interval * _), s_max)for _ in range(1, args.k+1)]

    score_split = [[] for _ in range(args.k)]
    for idxx, s in enumerate(scores_sorted):
        for idx, ref in enumerate(s_split):
            if s.item() <= ref:
                score_split[idx].append({indices[idxx].item():s.item()})
                break
    
    # 8. è¦†ç›–åº¦å¢å¼ºæ ·æœ¬é€‰æ‹©
    print(f"ğŸ¯ å¼€å§‹è¦†ç›–åº¦å¢å¼ºé€‰æ‹© (ç›®æ ‡: {args.n_fewshot}ä¸ªæ ·æœ¬)...")
    coreset = []
    m = args.n_fewshot
    round_num = 0
    
    while len(score_split):
        round_num += 1
        # select the group with fewest samples
        group = sorted(score_split, key=lambda x:len(x))
        if len(group) > 3:
            print(f"   ç¬¬{round_num}è½® - ç»„å¤§å°: {len(group[0])}, {len(group[1])}, {len(group[2])}, {len(group[3])}...")
        
        group = [strat for strat in group if len(strat)]
        if len(group) > 3:
            print(f"   è¿‡æ»¤ç©ºç»„å: {len(group[0])}, {len(group[1])}, {len(group[2])}, {len(group[3])}...")

        budget = min(len(group[0]), math.floor(m/len(group)))
        print(f"   å½“å‰è½®é¢„ç®—: {budget}")
        
        # random select and add to the fewshot indices list
        fewest = group[0]
        selected_idx = random.sample([list(_.keys())[0] for _ in fewest], budget)
        coreset.extend(selected_idx)

        # remove the fewest group
        score_split = group[1:]
        m = m - len(selected_idx)
        
    print(f"ğŸ‰ æ ·æœ¬é€‰æ‹©å®Œæˆ! å…±é€‰æ‹© {len(coreset)} ä¸ªæ ·æœ¬")

    # 9. ä¿å­˜ç»“æœ
    output_file = f"selected/{args.data_name}_{args.n_fewshot}.pt"
    torch.save(coreset, output_file)
    print(f"ğŸ’¾ ç»“æœä¿å­˜åˆ°: {output_file}")
    
    # 10. ä¿å­˜è¯¦ç»†ä¿¡æ¯
    result_info = {
        'coreset': coreset,
        'influence_scores': influence,
        'effort_scores': effort,
        'overall_scores': overall,
        'args': vars(args)
    }
    detailed_output = f"selected/{args.data_name}_{args.n_fewshot}_detailed.pt"
    torch.save(result_info, detailed_output)
    print(f"ğŸ“‹ è¯¦ç»†ä¿¡æ¯ä¿å­˜åˆ°: {detailed_output}")
    
    print("\n" + "="*60)
    print("ğŸš€ DEALRecæ•°æ®è£å‰ªå®Œæˆ!")
    print(f"âœ… é€‰æ‹©æ ·æœ¬æ•°: {len(coreset)}")
    print(f"âœ… ç¼“å­˜ç›®å½•: {cache_dir}")
    print(f"âœ… è¾“å‡ºæ–‡ä»¶: {output_file}")
    print("="*60)