#!/usr/bin/env python3
"""
è®­ç»ƒæ—¥å¿—åˆ†æå’Œå¯è§†åŒ–è„šæœ¬
ç”¨äºåˆ†æè®­ç»ƒè¿‡ç¨‹ä¸­çš„lossã€learning rateç­‰æŒ‡æ ‡å˜åŒ–
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import argparse
import os
from pathlib import Path

def plot_training_metrics(csv_file, output_dir=None):
    """
    ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡å›¾è¡¨
    """
    # è¯»å–æ—¥å¿—æ–‡ä»¶
    try:
        df = pd.read_csv(csv_file)
        print(f"ğŸ“Š æˆåŠŸè¯»å–æ—¥å¿—æ–‡ä»¶: {csv_file}")
        print(f"ğŸ“ˆ è®­ç»ƒè®°å½•æ•°: {len(df)}")
    except Exception as e:
        print(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
    plt.rcParams['font.size'] = 12
    plt.rcParams['figure.figsize'] = (15, 10)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if output_dir is None:
        output_dir = os.path.dirname(csv_file)
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºå­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('Training Metrics Dashboard', fontsize=16, fontweight='bold')
    
    # 1. æŸå¤±å‡½æ•°å˜åŒ–
    ax1 = axes[0, 0]
    if 'train_loss' in df.columns:
        train_mask = df['train_loss'] != 'N/A'
        if train_mask.any():
            ax1.plot(df[train_mask]['step'], pd.to_numeric(df[train_mask]['train_loss']), 
                    'b-', label='Train Loss', linewidth=2)
    
    if 'eval_loss' in df.columns:
        eval_mask = df['eval_loss'] != 'N/A'
        if eval_mask.any():
            ax1.plot(df[eval_mask]['step'], pd.to_numeric(df[eval_mask]['eval_loss']), 
                    'r-', label='Eval Loss', linewidth=2)
    
    ax1.set_xlabel('Training Steps')
    ax1.set_ylabel('Loss')
    ax1.set_title('Loss vs Training Steps')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. å­¦ä¹ ç‡å˜åŒ–
    ax2 = axes[0, 1]
    if 'learning_rate' in df.columns:
        lr_mask = df['learning_rate'] != 'N/A'
        if lr_mask.any():
            ax2.plot(df[lr_mask]['step'], pd.to_numeric(df[lr_mask]['learning_rate']), 
                    'g-', label='Learning Rate', linewidth=2)
    
    ax2.set_xlabel('Training Steps')
    ax2.set_ylabel('Learning Rate')
    ax2.set_title('Learning Rate Schedule')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
    
    # 3. Epoch vs Loss
    ax3 = axes[1, 0]
    if 'epoch' in df.columns and 'train_loss' in df.columns:
        train_mask = df['train_loss'] != 'N/A'
        if train_mask.any():
            ax3.plot(df[train_mask]['epoch'], pd.to_numeric(df[train_mask]['train_loss']), 
                    'b-', label='Train Loss', linewidth=2)
    
    if 'epoch' in df.columns and 'eval_loss' in df.columns:
        eval_mask = df['eval_loss'] != 'N/A'
        if eval_mask.any():
            ax3.plot(df[eval_mask]['epoch'], pd.to_numeric(df[eval_mask]['eval_loss']), 
                    'r-', label='Eval Loss', linewidth=2)
    
    ax3.set_xlabel('Epoch')
    ax3.set_ylabel('Loss')
    ax3.set_title('Loss vs Epoch')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. è®­ç»ƒæ—¶é—´ç»Ÿè®¡
    ax4 = axes[1, 1]
    if 'total_time' in df.columns:
        time_mask = df['total_time'] != 'N/A'
        if time_mask.any():
            total_times = pd.to_numeric(df[time_mask]['total_time'])
            ax4.plot(df[time_mask]['step'], total_times / 3600, 'purple', linewidth=2)  # è½¬æ¢ä¸ºå°æ—¶
    
    ax4.set_xlabel('Training Steps')
    ax4.set_ylabel('Training Time (Hours)')
    ax4.set_title('Training Time Progress')
    ax4.grid(True, alpha=0.3)
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    plot_file = os.path.join(output_dir, 'training_metrics.png')
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    print(f"ğŸ“ˆ è®­ç»ƒæŒ‡æ ‡å›¾è¡¨å·²ä¿å­˜: {plot_file}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š è®­ç»ƒç»Ÿè®¡æ‘˜è¦:")
    print("-" * 50)
    
    if 'train_loss' in df.columns:
        train_losses = pd.to_numeric(df[df['train_loss'] != 'N/A']['train_loss'])
        if len(train_losses) > 0:
            print(f"ğŸ”¥ è®­ç»ƒæŸå¤±: åˆå§‹={train_losses.iloc[0]:.4f}, æœ€ç»ˆ={train_losses.iloc[-1]:.4f}")
            print(f"ğŸ“‰ æŸå¤±ä¸‹é™: {((train_losses.iloc[0] - train_losses.iloc[-1]) / train_losses.iloc[0] * 100):.2f}%")
    
    if 'eval_loss' in df.columns:
        eval_losses = pd.to_numeric(df[df['eval_loss'] != 'N/A']['eval_loss'])
        if len(eval_losses) > 0:
            print(f"âœ… éªŒè¯æŸå¤±: æœ€ä½³={eval_losses.min():.4f}")
    
    if 'total_time' in df.columns:
        total_times = pd.to_numeric(df[df['total_time'] != 'N/A']['total_time'])
        if len(total_times) > 0:
            print(f"â° è®­ç»ƒæ—¶é—´: {total_times.iloc[-1] / 3600:.2f} å°æ—¶")
    
    if 'epoch' in df.columns:
        epochs = pd.to_numeric(df[df['epoch'] != 'N/A']['epoch'])
        if len(epochs) > 0:
            print(f"ğŸ“š å®Œæˆè½®æ•°: {epochs.iloc[-1]:.2f} epochs")
    
    return df

def compare_training_runs(csv_files, labels=None, output_dir="./comparison"):
    """
    å¯¹æ¯”å¤šä¸ªè®­ç»ƒè¿è¡Œçš„ç»“æœ
    """
    if labels is None:
        labels = [f"Run {i+1}" for i in range(len(csv_files))]
    
    plt.figure(figsize=(15, 5))
    
    # å¯¹æ¯”è®­ç»ƒæŸå¤±
    plt.subplot(1, 3, 1)
    for csv_file, label in zip(csv_files, labels):
        try:
            df = pd.read_csv(csv_file)
            train_mask = df['train_loss'] != 'N/A'
            if train_mask.any():
                plt.plot(df[train_mask]['step'], pd.to_numeric(df[train_mask]['train_loss']), 
                        label=f'{label} - Train', linewidth=2)
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å– {csv_file}: {e}")
    
    plt.xlabel('Training Steps')
    plt.ylabel('Train Loss')
    plt.title('Training Loss Comparison')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å¯¹æ¯”éªŒè¯æŸå¤±
    plt.subplot(1, 3, 2)
    for csv_file, label in zip(csv_files, labels):
        try:
            df = pd.read_csv(csv_file)
            eval_mask = df['eval_loss'] != 'N/A'
            if eval_mask.any():
                plt.plot(df[eval_mask]['step'], pd.to_numeric(df[eval_mask]['eval_loss']), 
                        label=f'{label} - Eval', linewidth=2)
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å– {csv_file}: {e}")
    
    plt.xlabel('Training Steps')
    plt.ylabel('Eval Loss')
    plt.title('Validation Loss Comparison')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å¯¹æ¯”å­¦ä¹ ç‡
    plt.subplot(1, 3, 3)
    for csv_file, label in zip(csv_files, labels):
        try:
            df = pd.read_csv(csv_file)
            lr_mask = df['learning_rate'] != 'N/A'
            if lr_mask.any():
                plt.plot(df[lr_mask]['step'], pd.to_numeric(df[lr_mask]['learning_rate']), 
                        label=f'{label} - LR', linewidth=2)
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å– {csv_file}: {e}")
    
    plt.xlabel('Training Steps')
    plt.ylabel('Learning Rate')
    plt.title('Learning Rate Comparison')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
    
    plt.tight_layout()
    
    # ä¿å­˜å¯¹æ¯”å›¾
    os.makedirs(output_dir, exist_ok=True)
    comparison_file = os.path.join(output_dir, 'training_comparison.png')
    plt.savefig(comparison_file, dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š è®­ç»ƒå¯¹æ¯”å›¾å·²ä¿å­˜: {comparison_file}")

def main():
    parser = argparse.ArgumentParser(description="è®­ç»ƒæ—¥å¿—åˆ†æå’Œå¯è§†åŒ–")
    parser.add_argument("--log_file", type=str, required=True, help="è®­ç»ƒæ—¥å¿—CSVæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output_dir", type=str, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--compare", nargs="+", help="å¯¹æ¯”å¤šä¸ªæ—¥å¿—æ–‡ä»¶")
    parser.add_argument("--labels", nargs="+", help="å¯¹æ¯”å›¾çš„æ ‡ç­¾")
    
    args = parser.parse_args()
    
    if args.compare:
        print("ğŸ“Š å¼€å§‹å¯¹æ¯”åˆ†æå¤šä¸ªè®­ç»ƒè¿è¡Œ...")
        compare_training_runs(args.compare, args.labels, args.output_dir or "./comparison")
    else:
        print("ğŸ“ˆ å¼€å§‹åˆ†æå•ä¸ªè®­ç»ƒè¿è¡Œ...")
        plot_training_metrics(args.log_file, args.output_dir)

if __name__ == "__main__":
    main() 