NVIDIA GeForce RTX 4090

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /root/miniconda3/envs/DEALRec/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.9
CUDA SETUP: Detected CUDA version 118
CUDA SETUP: Loading binary /root/miniconda3/envs/DEALRec/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...
Training Alpaca-LoRA model with params:
base_model: /root/autodl-tmp/nku/DEALRec-main/models_cache/models--yahma--llama-7b-hf/snapshots/cf33055e5df9cc533abd7ea4707bf727ca2ada75
train_data_path: ./data/games/train/train-1024.json
val_data_path: ./data/games/valid/valid-1024.json
sample: 1024
seed: 2023
output_dir: ./model/games/2023_1024
batch_size: 128
micro_batch_size: 16
num_epochs: 30
learning_rate: 0.0001
cutoff_len: 512
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q_proj', 'v_proj', 'k_proj', 'o_proj']
train_on_inputs: True
group_by_length: True
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: None

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.01s/it]
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
/root/miniconda3/envs/DEALRec/lib/python3.8/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.
  warnings.warn(
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Loading training data from: ./data/games/train/train-1024.json
Loading validation data from: ./data/games/valid/valid-1024.json
trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.12433454005023165
  0%|          | 0/240 [00:00<?, ?it/s]/root/miniconda3/envs/DEALRec/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  0%|          | 1/240 [00:23<1:34:17, 23.67s/it]                                                   0%|          | 1/240 [00:23<1:34:17, 23.67s/it]  1%|          | 2/240 [00:37<1:10:55, 17.88s/it]  1%|▏         | 3/240 [01:00<1:19:04, 20.02s/it]  2%|▏         | 4/240 [01:13<1:08:59, 17.54s/it]  2%|▏         | 5/240 [01:37<1:16:59, 19.66s/it]                                                   2%|▏         | 5/240 [01:37<1:16:59, 19.66s/it]  2%|▎         | 6/240 [01:51<1:09:11, 17.74s/it]  3%|▎         | 7/240 [02:15<1:17:45, 20.02s/it]  3%|▎         | 8/240 [02:29<1:09:50, 18.06s/it]  4%|▍         | 9/240 [02:53<1:16:05, 19.76s/it]  4%|▍         | 10/240 [03:07<1:08:40, 17.92s/it]                                                    4%|▍         | 10/240 [03:07<1:08:40, 17.92s/it]  5%|▍         | 11/240 [03:29<1:13:41, 19.31s/it]  5%|▌         | 12/240 [03:43<1:07:04, 17.65s/it]  5%|▌         | 13/240 [04:08<1:15:47, 20.03s/it]  6%|▌         | 14/240 [04:23<1:08:40, 18.23s/it]  6%|▋         | 15/240 [04:45<1:13:06, 19.50s/it]                                                    6%|▋         | 15/240 [04:45<1:13:06, 19.50s/it]  7%|▋         | 16/240 [04:59<1:06:19, 17.76s/it]  7%|▋         | 17/240 [05:23<1:13:24, 19.75s/it]  8%|▊         | 18/240 [05:37<1:06:30, 17.98s/it]  8%|▊         | 19/240 [06:00<1:12:09, 19.59s/it]  8%|▊         | 20/240 [06:14<1:05:35, 17.89s/it]                                                    8%|▊         | 20/240 [06:14<1:05:35, 17.89s/it]  9%|▉         | 21/240 [06:37<1:10:51, 19.41s/it]  9%|▉         | 22/240 [06:51<1:04:36, 17.78s/it] 10%|▉         | 23/240 [07:14<1:09:56, 19.34s/it] 10%|█         | 24/240 [07:28<1:03:43, 17.70s/it] 10%|█         | 25/240 [07:52<1:09:44, 19.46s/it]                                                   10%|█         | 25/240 [07:52<1:09:44, 19.46s/it] 11%|█         | 26/240 [08:05<1:03:29, 17.80s/it] 11%|█▏        | 27/240 [08:28<1:08:40, 19.35s/it] 12%|█▏        | 28/240 [08:42<1:02:26, 17.67s/it] 12%|█▏        | 29/240 [09:06<1:08:24, 19.45s/it] 12%|█▎        | 30/240 [09:20<1:02:12, 17.78s/it]                                                   12%|█▎        | 30/240 [09:20<1:02:12, 17.78s/it] 13%|█▎        | 31/240 [09:43<1:07:50, 19.48s/it] 13%|█▎        | 32/240 [09:57<1:01:34, 17.76s/it] 14%|█▍        | 33/240 [10:20<1:06:39, 19.32s/it] 14%|█▍        | 34/240 [10:34<1:00:41, 17.68s/it] 15%|█▍        | 35/240 [10:57<1:05:47, 19.26s/it]                                                   15%|█▍        | 35/240 [10:57<1:05:47, 19.26s/it] 15%|█▌        | 36/240 [11:10<59:54, 17.62s/it]   15%|█▌        | 37/240 [11:34<1:05:51, 19.47s/it] 16%|█▌        | 38/240 [11:48<59:59, 17.82s/it]   16%|█▋        | 39/240 [12:11<1:05:08, 19.45s/it] 17%|█▋        | 40/240 [12:25<59:05, 17.73s/it]                                                   17%|█▋        | 40/240 [12:25<59:05, 17.73s/it] 17%|█▋        | 41/240 [12:48<1:04:03, 19.31s/it] 18%|█▊        | 42/240 [13:02<58:17, 17.66s/it]   18%|█▊        | 43/240 [13:27<1:04:59, 19.80s/it] 18%|█▊        | 44/240 [13:41<58:56, 18.04s/it]   19%|█▉        | 45/240 [14:04<1:03:37, 19.58s/it]                                                   19%|█▉        | 45/240 [14:04<1:03:37, 19.58s/it] 19%|█▉        | 46/240 [14:18<57:47, 17.87s/it]   20%|█▉        | 47/240 [14:41<1:02:14, 19.35s/it] 20%|██        | 48/240 [14:54<56:30, 17.66s/it]   20%|██        | 49/240 [15:17<1:01:24, 19.29s/it] 21%|██        | 50/240 [15:31<55:53, 17.65s/it]                                                   21%|██        | 50/240 [15:31<55:53, 17.65s/it]📊 [训练日志] Epoch: 0.12, Step: 1, Train Loss: N/A, Eval Loss: N/A, LR: 5e-06
{'loss': 2.4355, 'learning_rate': 5e-06, 'epoch': 0.12}
📊 [训练日志] Epoch: 0.62, Step: 5, Train Loss: N/A, Eval Loss: N/A, LR: 2.5e-05
{'loss': 2.6336, 'learning_rate': 2.5e-05, 'epoch': 0.62}
📊 [训练日志] Epoch: 1.25, Step: 10, Train Loss: N/A, Eval Loss: N/A, LR: 5e-05
{'loss': 2.6107, 'learning_rate': 5e-05, 'epoch': 1.25}
📊 [训练日志] Epoch: 1.88, Step: 15, Train Loss: N/A, Eval Loss: N/A, LR: 7.500000000000001e-05
{'loss': 2.4339, 'learning_rate': 7.500000000000001e-05, 'epoch': 1.88}
📊 [训练日志] Epoch: 2.50, Step: 20, Train Loss: N/A, Eval Loss: N/A, LR: 0.0001
{'loss': 2.2647, 'learning_rate': 0.0001, 'epoch': 2.5}
📊 [训练日志] Epoch: 3.12, Step: 25, Train Loss: N/A, Eval Loss: N/A, LR: 9.772727272727274e-05
{'loss': 1.8633, 'learning_rate': 9.772727272727274e-05, 'epoch': 3.12}
📊 [训练日志] Epoch: 3.75, Step: 30, Train Loss: N/A, Eval Loss: N/A, LR: 9.545454545454546e-05
{'loss': 1.4359, 'learning_rate': 9.545454545454546e-05, 'epoch': 3.75}
📊 [训练日志] Epoch: 4.38, Step: 35, Train Loss: N/A, Eval Loss: N/A, LR: 9.318181818181818e-05
{'loss': 1.1569, 'learning_rate': 9.318181818181818e-05, 'epoch': 4.38}
📊 [训练日志] Epoch: 5.00, Step: 40, Train Loss: N/A, Eval Loss: N/A, LR: 9.090909090909092e-05
{'loss': 0.9762, 'learning_rate': 9.090909090909092e-05, 'epoch': 5.0}
📊 [训练日志] Epoch: 5.62, Step: 45, Train Loss: N/A, Eval Loss: N/A, LR: 8.863636363636364e-05
{'loss': 0.9493, 'learning_rate': 8.863636363636364e-05, 'epoch': 5.62}
📊 [训练日志] Epoch: 6.25, Step: 50, Train Loss: N/A, Eval Loss: N/A, LR: 8.636363636363637e-05
{'loss': 0.8271, 'learning_rate': 8.636363636363637e-05, 'epoch': 6.25}

  0%|          | 0/12 [00:00<?, ?it/s][A
 17%|█▋        | 2/12 [00:00<00:04,  2.17it/s][A
 25%|██▌       | 3/12 [00:02<00:07,  1.17it/s][A
 33%|███▎      | 4/12 [00:03<00:08,  1.04s/it][A
 42%|████▏     | 5/12 [00:05<00:08,  1.17s/it][A
 50%|█████     | 6/12 [00:06<00:07,  1.25s/it][A
 58%|█████▊    | 7/12 [00:07<00:06,  1.22s/it][A
 67%|██████▋   | 8/12 [00:08<00:04,  1.18s/it][A
 75%|███████▌  | 9/12 [00:09<00:03,  1.10s/it][A
 83%|████████▎ | 10/12 [00:10<00:02,  1.01s/it][A
 92%|█████████▏| 11/12 [00:11<00:00,  1.10it/s][A
100%|██████████| 12/12 [00:11<00:00,  1.13it/s][A                                                
                                               [A 21%|██        | 50/240 [15:44<55:53, 17.65s/it]
100%|██████████| 12/12 [00:12<00:00,  1.13it/s][A
                                               [A 21%|██▏       | 51/240 [16:07<1:13:00, 23.18s/it] 22%|██▏       | 52/240 [16:21<1:03:54, 20.39s/it] 22%|██▏       | 53/240 [16:44<1:06:13, 21.25s/it] 22%|██▎       | 54/240 [16:58<58:56, 19.02s/it]   23%|██▎       | 55/240 [17:22<1:02:46, 20.36s/it]                                                   23%|██▎       | 55/240 [17:22<1:02:46, 20.36s/it] 23%|██▎       | 56/240 [17:35<56:21, 18.38s/it]   24%|██▍       | 57/240 [17:59<1:00:39, 19.89s/it] 24%|██▍       | 58/240 [18:12<54:37, 18.01s/it]   25%|██▍       | 59/240 [18:35<58:20, 19.34s/it] 25%|██▌       | 60/240 [18:49<53:01, 17.68s/it]                                                 25%|██▌       | 60/240 [18:49<53:01, 17.68s/it] 25%|██▌       | 61/240 [19:12<57:43, 19.35s/it] 26%|██▌       | 62/240 [19:26<52:37, 17.74s/it] 26%|██▋       | 63/240 [19:50<58:19, 19.77s/it] 27%|██▋       | 64/240 [20:04<52:57, 18.05s/it] 27%|██▋       | 65/240 [20:27<56:43, 19.45s/it]                                                 27%|██▋       | 65/240 [20:27<56:43, 19.45s/it] 28%|██▊       | 66/240 [20:41<51:10, 17.65s/it] 28%|██▊       | 67/240 [21:04<55:30, 19.25s/it] 28%|██▊       | 68/240 [21:17<50:33, 17.64s/it] 29%|██▉       | 69/240 [21:42<55:52, 19.61s/it] 29%|██▉       | 70/240 [21:56<50:49, 17.94s/it]                                                 29%|██▉       | 70/240 [21:56<50:49, 17.94s/it] 30%|██▉       | 71/240 [22:19<55:10, 19.59s/it] 30%|███       | 72/240 [22:33<50:07, 17.90s/it] 30%|███       | 73/240 [22:57<54:23, 19.54s/it] 31%|███       | 74/240 [23:10<49:08, 17.76s/it] 31%|███▏      | 75/240 [23:33<53:08, 19.33s/it]                                                 31%|███▏      | 75/240 [23:33<53:08, 19.33s/it] 32%|███▏      | 76/240 [23:47<48:27, 17.73s/it] 32%|███▏      | 77/240 [24:11<53:01, 19.52s/it] 32%|███▎      | 78/240 [24:25<48:12, 17.86s/it] 33%|███▎      | 79/240 [24:48<52:04, 19.41s/it] 33%|███▎      | 80/240 [25:02<47:19, 17.75s/it]                                                 33%|███▎      | 80/240 [25:02<47:19, 17.75s/it] 34%|███▍      | 81/240 [25:25<51:39, 19.49s/it] 34%|███▍      | 82/240 [25:39<46:45, 17.76s/it] 35%|███▍      | 83/240 [26:03<51:41, 19.75s/it] 35%|███▌      | 84/240 [26:17<46:54, 18.04s/it] 35%|███▌      | 85/240 [26:41<50:46, 19.66s/it]                                                 35%|███▌      | 85/240 [26:41<50:46, 19.66s/it] 36%|███▌      | 86/240 [26:55<45:59, 17.92s/it] 36%|███▋      | 87/240 [27:17<49:13, 19.30s/it] 37%|███▋      | 88/240 [27:31<44:36, 17.61s/it] 37%|███▋      | 89/240 [27:54<48:17, 19.19s/it] 38%|███▊      | 90/240 [28:08<43:56, 17.58s/it]                                                 38%|███▊      | 90/240 [28:08<43:56, 17.58s/it] 38%|███▊      | 91/240 [28:31<48:21, 19.47s/it] 38%|███▊      | 92/240 [28:46<44:01, 17.85s/it] 39%|███▉      | 93/240 [29:08<47:12, 19.27s/it] 39%|███▉      | 94/240 [29:22<42:54, 17.63s/it] 40%|███▉      | 95/240 [29:46<47:06, 19.50s/it]                                                 40%|███▉      | 95/240 [29:46<47:06, 19.50s/it] 40%|████      | 96/240 [29:59<42:37, 17.76s/it] 40%|████      | 97/240 [30:23<46:17, 19.42s/it] 41%|████      | 98/240 [30:36<41:53, 17.70s/it] 41%|████▏     | 99/240 [31:00<45:47, 19.49s/it] 42%|████▏     | 100/240 [31:14<41:30, 17.79s/it]                                                  42%|████▏     | 100/240 [31:14<41:30, 17.79s/it]📊 [训练日志] Epoch: 6.25, Step: 50, Train Loss: N/A, Eval Loss: 1.0628026723861694, LR: N/A
{'eval_loss': 1.0628026723861694, 'eval_runtime': 12.7505, 'eval_samples_per_second': 15.058, 'eval_steps_per_second': 0.941, 'epoch': 6.25}
📊 [训练日志] Epoch: 6.88, Step: 55, Train Loss: N/A, Eval Loss: N/A, LR: 8.40909090909091e-05
{'loss': 0.7771, 'learning_rate': 8.40909090909091e-05, 'epoch': 6.88}
📊 [训练日志] Epoch: 7.50, Step: 60, Train Loss: N/A, Eval Loss: N/A, LR: 8.181818181818183e-05
{'loss': 0.6352, 'learning_rate': 8.181818181818183e-05, 'epoch': 7.5}
📊 [训练日志] Epoch: 8.12, Step: 65, Train Loss: N/A, Eval Loss: N/A, LR: 7.954545454545455e-05
{'loss': 0.7279, 'learning_rate': 7.954545454545455e-05, 'epoch': 8.12}
📊 [训练日志] Epoch: 8.75, Step: 70, Train Loss: N/A, Eval Loss: N/A, LR: 7.727272727272727e-05
{'loss': 0.6254, 'learning_rate': 7.727272727272727e-05, 'epoch': 8.75}
📊 [训练日志] Epoch: 9.38, Step: 75, Train Loss: N/A, Eval Loss: N/A, LR: 7.500000000000001e-05
{'loss': 0.7037, 'learning_rate': 7.500000000000001e-05, 'epoch': 9.38}
📊 [训练日志] Epoch: 10.00, Step: 80, Train Loss: N/A, Eval Loss: N/A, LR: 7.272727272727273e-05
{'loss': 0.6261, 'learning_rate': 7.272727272727273e-05, 'epoch': 10.0}
📊 [训练日志] Epoch: 10.62, Step: 85, Train Loss: N/A, Eval Loss: N/A, LR: 7.045454545454546e-05
{'loss': 0.69, 'learning_rate': 7.045454545454546e-05, 'epoch': 10.62}
📊 [训练日志] Epoch: 11.25, Step: 90, Train Loss: N/A, Eval Loss: N/A, LR: 6.818181818181818e-05
{'loss': 0.6062, 'learning_rate': 6.818181818181818e-05, 'epoch': 11.25}
📊 [训练日志] Epoch: 11.88, Step: 95, Train Loss: N/A, Eval Loss: N/A, LR: 6.59090909090909e-05
{'loss': 0.7011, 'learning_rate': 6.59090909090909e-05, 'epoch': 11.88}
📊 [训练日志] Epoch: 12.50, Step: 100, Train Loss: N/A, Eval Loss: N/A, LR: 6.363636363636364e-05
{'loss': 0.6065, 'learning_rate': 6.363636363636364e-05, 'epoch': 12.5}

  0%|          | 0/12 [00:00<?, ?it/s][A
 17%|█▋        | 2/12 [00:00<00:04,  2.17it/s][A
 25%|██▌       | 3/12 [00:02<00:07,  1.17it/s][A
 33%|███▎      | 4/12 [00:03<00:08,  1.04s/it][A
 42%|████▏     | 5/12 [00:05<00:08,  1.17s/it][A
 50%|█████     | 6/12 [00:06<00:07,  1.25s/it][A
 58%|█████▊    | 7/12 [00:07<00:06,  1.22s/it][A
 67%|██████▋   | 8/12 [00:08<00:04,  1.18s/it][A
 75%|███████▌  | 9/12 [00:09<00:03,  1.10s/it][A
 83%|████████▎ | 10/12 [00:10<00:02,  1.02s/it][A
 92%|█████████▏| 11/12 [00:11<00:00,  1.09it/s][A
100%|██████████| 12/12 [00:12<00:00,  1.12it/s][A                                                 
                                               [A 42%|████▏     | 100/240 [31:27<41:30, 17.79s/it]
100%|██████████| 12/12 [00:12<00:00,  1.12it/s][A
                                               [A 42%|████▏     | 101/240 [31:50<53:42, 23.18s/it] 42%|████▎     | 102/240 [32:04<46:52, 20.38s/it] 43%|████▎     | 103/240 [32:27<48:23, 21.20s/it] 43%|████▎     | 104/240 [32:40<43:02, 18.99s/it] 44%|████▍     | 105/240 [33:04<45:34, 20.26s/it]                                                  44%|████▍     | 105/240 [33:04<45:34, 20.26s/it] 44%|████▍     | 106/240 [33:18<40:58, 18.35s/it] 45%|████▍     | 107/240 [33:41<43:53, 19.80s/it] 45%|████▌     | 108/240 [33:55<39:40, 18.03s/it] 45%|████▌     | 109/240 [34:18<42:45, 19.59s/it] 46%|████▌     | 110/240 [34:32<38:36, 17.82s/it]                                                  46%|████▌     | 110/240 [34:32<38:36, 17.82s/it] 46%|████▋     | 111/240 [34:55<42:11, 19.63s/it] 47%|████▋     | 112/240 [35:09<38:00, 17.81s/it] 47%|████▋     | 113/240 [35:32<41:05, 19.41s/it] 48%|████▊     | 114/240 [35:46<37:16, 17.75s/it] 48%|████▊     | 115/240 [36:10<40:50, 19.60s/it]                                                  48%|████▊     | 115/240 [36:10<40:50, 19.60s/it] 48%|████▊     | 116/240 [36:24<36:56, 17.88s/it] 49%|████▉     | 117/240 [36:47<40:05, 19.56s/it] 49%|████▉     | 118/240 [37:01<36:19, 17.86s/it] 50%|████▉     | 119/240 [37:24<38:55, 19.30s/it] 50%|█████     | 120/240 [37:37<35:11, 17.59s/it]                                                  50%|█████     | 120/240 [37:37<35:11, 17.59s/it] 50%|█████     | 121/240 [38:01<38:39, 19.49s/it] 51%|█████     | 122/240 [38:15<34:55, 17.76s/it] 51%|█████▏    | 123/240 [38:38<37:38, 19.31s/it] 52%|█████▏    | 124/240 [38:52<34:16, 17.72s/it] 52%|█████▏    | 125/240 [39:16<37:16, 19.44s/it]                                                  52%|█████▏    | 125/240 [39:16<37:16, 19.44s/it] 52%|█████▎    | 126/240 [39:29<33:46, 17.78s/it] 53%|█████▎    | 127/240 [39:52<36:25, 19.34s/it] 53%|█████▎    | 128/240 [40:06<32:56, 17.65s/it] 54%|█████▍    | 129/240 [40:30<36:17, 19.62s/it] 54%|█████▍    | 130/240 [40:44<32:47, 17.88s/it]                                                  54%|█████▍    | 130/240 [40:44<32:47, 17.88s/it] 55%|█████▍    | 131/240 [41:07<35:18, 19.43s/it] 55%|█████▌    | 132/240 [41:21<31:55, 17.73s/it] 55%|█████▌    | 133/240 [41:44<34:27, 19.32s/it] 56%|█████▌    | 134/240 [41:58<31:09, 17.64s/it] 56%|█████▋    | 135/240 [42:21<33:39, 19.23s/it]                                                  56%|█████▋    | 135/240 [42:21<33:39, 19.23s/it] 57%|█████▋    | 136/240 [42:35<30:33, 17.63s/it] 57%|█████▋    | 137/240 [42:57<32:59, 19.22s/it] 57%|█████▊    | 138/240 [43:11<29:52, 17.58s/it] 58%|█████▊    | 139/240 [43:35<32:41, 19.42s/it] 58%|█████▊    | 140/240 [43:49<29:39, 17.80s/it]                                                  58%|█████▊    | 140/240 [43:49<29:39, 17.80s/it] 59%|█████▉    | 141/240 [44:12<31:48, 19.28s/it] 59%|█████▉    | 142/240 [44:25<28:48, 17.64s/it] 60%|█████▉    | 143/240 [44:50<31:48, 19.67s/it] 60%|██████    | 144/240 [45:04<28:38, 17.90s/it] 60%|██████    | 145/240 [45:27<30:51, 19.49s/it]                                                  60%|██████    | 145/240 [45:27<30:51, 19.49s/it] 61%|██████    | 146/240 [45:41<27:50, 17.77s/it] 61%|██████▏   | 147/240 [46:04<30:02, 19.38s/it] 62%|██████▏   | 148/240 [46:18<27:11, 17.73s/it] 62%|██████▏   | 149/240 [46:41<29:23, 19.38s/it] 62%|██████▎   | 150/240 [46:55<26:29, 17.66s/it]                                                  62%|██████▎   | 150/240 [46:55<26:29, 17.66s/it]📊 [训练日志] Epoch: 12.50, Step: 100, Train Loss: N/A, Eval Loss: 0.8700583577156067, LR: N/A
{'eval_loss': 0.8700583577156067, 'eval_runtime': 12.7841, 'eval_samples_per_second': 15.019, 'eval_steps_per_second': 0.939, 'epoch': 12.5}
📊 [训练日志] Epoch: 13.12, Step: 105, Train Loss: N/A, Eval Loss: N/A, LR: 6.136363636363636e-05
{'loss': 0.6746, 'learning_rate': 6.136363636363636e-05, 'epoch': 13.12}
📊 [训练日志] Epoch: 13.75, Step: 110, Train Loss: N/A, Eval Loss: N/A, LR: 5.90909090909091e-05
{'loss': 0.6117, 'learning_rate': 5.90909090909091e-05, 'epoch': 13.75}
📊 [训练日志] Epoch: 14.38, Step: 115, Train Loss: N/A, Eval Loss: N/A, LR: 5.6818181818181825e-05
{'loss': 0.6704, 'learning_rate': 5.6818181818181825e-05, 'epoch': 14.38}
📊 [训练日志] Epoch: 15.00, Step: 120, Train Loss: N/A, Eval Loss: N/A, LR: 5.4545454545454546e-05
{'loss': 0.598, 'learning_rate': 5.4545454545454546e-05, 'epoch': 15.0}
📊 [训练日志] Epoch: 15.62, Step: 125, Train Loss: N/A, Eval Loss: N/A, LR: 5.2272727272727274e-05
{'loss': 0.6725, 'learning_rate': 5.2272727272727274e-05, 'epoch': 15.62}
📊 [训练日志] Epoch: 16.25, Step: 130, Train Loss: N/A, Eval Loss: N/A, LR: 5e-05
{'loss': 0.6006, 'learning_rate': 5e-05, 'epoch': 16.25}
📊 [训练日志] Epoch: 16.88, Step: 135, Train Loss: N/A, Eval Loss: N/A, LR: 4.772727272727273e-05
{'loss': 0.6612, 'learning_rate': 4.772727272727273e-05, 'epoch': 16.88}
📊 [训练日志] Epoch: 17.50, Step: 140, Train Loss: N/A, Eval Loss: N/A, LR: 4.545454545454546e-05
{'loss': 0.5875, 'learning_rate': 4.545454545454546e-05, 'epoch': 17.5}
📊 [训练日志] Epoch: 18.12, Step: 145, Train Loss: N/A, Eval Loss: N/A, LR: 4.318181818181819e-05
{'loss': 0.6595, 'learning_rate': 4.318181818181819e-05, 'epoch': 18.12}
📊 [训练日志] Epoch: 18.75, Step: 150, Train Loss: N/A, Eval Loss: N/A, LR: 4.0909090909090915e-05
{'loss': 0.5842, 'learning_rate': 4.0909090909090915e-05, 'epoch': 18.75}

  0%|          | 0/12 [00:00<?, ?it/s][A
 17%|█▋        | 2/12 [00:00<00:04,  2.15it/s][A
 25%|██▌       | 3/12 [00:02<00:07,  1.17it/s][A
 33%|███▎      | 4/12 [00:03<00:08,  1.05s/it][A
 42%|████▏     | 5/12 [00:05<00:08,  1.17s/it][A
 50%|█████     | 6/12 [00:06<00:07,  1.25s/it][A
 58%|█████▊    | 7/12 [00:07<00:06,  1.22s/it][A
 67%|██████▋   | 8/12 [00:08<00:04,  1.18s/it][A
 75%|███████▌  | 9/12 [00:09<00:03,  1.10s/it][A
 83%|████████▎ | 10/12 [00:10<00:02,  1.02s/it][A
 92%|█████████▏| 11/12 [00:11<00:00,  1.09it/s][A
100%|██████████| 12/12 [00:12<00:00,  1.12it/s][A                                                 
                                               [A 62%|██████▎   | 150/240 [47:07<26:29, 17.66s/it]
100%|██████████| 12/12 [00:12<00:00,  1.12it/s][A
                                               [A 63%|██████▎   | 151/240 [47:31<34:31, 23.27s/it] 63%|██████▎   | 152/240 [47:45<30:02, 20.49s/it] 64%|██████▍   | 153/240 [48:08<30:51, 21.29s/it] 64%|██████▍   | 154/240 [48:22<27:18, 19.05s/it] 65%|██████▍   | 155/240 [48:45<28:31, 20.14s/it]                                                  65%|██████▍   | 155/240 [48:45<28:31, 20.14s/it] 65%|██████▌   | 156/240 [48:58<25:33, 18.26s/it] 65%|██████▌   | 157/240 [49:22<27:35, 19.95s/it] 66%|██████▌   | 158/240 [49:36<24:46, 18.13s/it] 66%|██████▋   | 159/240 [50:00<26:39, 19.75s/it] 67%|██████▋   | 160/240 [50:14<23:57, 17.97s/it]                                                  67%|██████▋   | 160/240 [50:14<23:57, 17.97s/it] 67%|██████▋   | 161/240 [50:37<25:42, 19.53s/it] 68%|██████▊   | 162/240 [50:51<23:11, 17.84s/it] 68%|██████▊   | 163/240 [51:14<25:03, 19.53s/it] 68%|██████▊   | 164/240 [51:28<22:35, 17.83s/it] 69%|██████▉   | 165/240 [51:51<24:19, 19.47s/it]                                                  69%|██████▉   | 165/240 [51:51<24:19, 19.47s/it] 69%|██████▉   | 166/240 [52:05<21:53, 17.75s/it] 70%|██████▉   | 167/240 [52:28<23:40, 19.46s/it] 70%|███████   | 168/240 [52:42<21:16, 17.73s/it] 70%|███████   | 169/240 [53:05<22:58, 19.42s/it] 71%|███████   | 170/240 [53:20<20:46, 17.81s/it]                                                  71%|███████   | 170/240 [53:20<20:46, 17.81s/it] 71%|███████▏  | 171/240 [53:44<22:47, 19.81s/it] 72%|███████▏  | 172/240 [53:58<20:24, 18.01s/it] 72%|███████▏  | 173/240 [54:21<21:48, 19.53s/it] 72%|███████▎  | 174/240 [54:35<19:33, 17.78s/it] 73%|███████▎  | 175/240 [54:58<21:00, 19.39s/it]                                                  73%|███████▎  | 175/240 [54:58<21:00, 19.39s/it] 73%|███████▎  | 176/240 [55:12<18:52, 17.70s/it] 74%|███████▍  | 177/240 [55:36<20:36, 19.63s/it] 74%|███████▍  | 178/240 [55:49<18:28, 17.87s/it] 75%|███████▍  | 179/240 [56:13<19:50, 19.52s/it] 75%|███████▌  | 180/240 [56:27<17:46, 17.78s/it]                                                  75%|███████▌  | 180/240 [56:27<17:46, 17.78s/it] 75%|███████▌  | 181/240 [56:49<18:57, 19.28s/it] 76%|███████▌  | 182/240 [57:03<17:02, 17.64s/it] 76%|███████▋  | 183/240 [57:26<18:23, 19.37s/it] 77%|███████▋  | 184/240 [57:41<16:36, 17.79s/it] 77%|███████▋  | 185/240 [58:03<17:41, 19.31s/it]                                                  77%|███████▋  | 185/240 [58:03<17:41, 19.31s/it] 78%|███████▊  | 186/240 [58:17<15:54, 17.67s/it] 78%|███████▊  | 187/240 [58:40<16:58, 19.22s/it] 78%|███████▊  | 188/240 [58:54<15:13, 17.57s/it] 79%|███████▉  | 189/240 [59:17<16:22, 19.26s/it] 79%|███████▉  | 190/240 [59:31<14:40, 17.61s/it]                                                  79%|███████▉  | 190/240 [59:31<14:40, 17.61s/it] 80%|███████▉  | 191/240 [59:56<16:11, 19.83s/it] 80%|████████  | 192/240 [1:00:10<14:28, 18.10s/it] 80%|████████  | 193/240 [1:00:33<15:15, 19.48s/it] 81%|████████  | 194/240 [1:00:46<13:33, 17.69s/it] 81%|████████▏ | 195/240 [1:01:10<14:39, 19.55s/it]                                                    81%|████████▏ | 195/240 [1:01:10<14:39, 19.55s/it] 82%|████████▏ | 196/240 [1:01:24<13:02, 17.79s/it] 82%|████████▏ | 197/240 [1:01:47<14:00, 19.55s/it] 82%|████████▎ | 198/240 [1:02:01<12:32, 17.93s/it] 83%|████████▎ | 199/240 [1:02:25<13:18, 19.48s/it] 83%|████████▎ | 200/240 [1:02:39<11:52, 17.81s/it]                                                    83%|████████▎ | 200/240 [1:02:39<11:52, 17.81s/it]📊 [训练日志] Epoch: 18.75, Step: 150, Train Loss: N/A, Eval Loss: 0.8469192385673523, LR: N/A
{'eval_loss': 0.8469192385673523, 'eval_runtime': 12.805, 'eval_samples_per_second': 14.994, 'eval_steps_per_second': 0.937, 'epoch': 18.75}
📊 [训练日志] Epoch: 19.38, Step: 155, Train Loss: N/A, Eval Loss: N/A, LR: 3.8636363636363636e-05
{'loss': 0.6546, 'learning_rate': 3.8636363636363636e-05, 'epoch': 19.38}
📊 [训练日志] Epoch: 20.00, Step: 160, Train Loss: N/A, Eval Loss: N/A, LR: 3.6363636363636364e-05
{'loss': 0.5942, 'learning_rate': 3.6363636363636364e-05, 'epoch': 20.0}
📊 [训练日志] Epoch: 20.62, Step: 165, Train Loss: N/A, Eval Loss: N/A, LR: 3.409090909090909e-05
{'loss': 0.6577, 'learning_rate': 3.409090909090909e-05, 'epoch': 20.62}
📊 [训练日志] Epoch: 21.25, Step: 170, Train Loss: N/A, Eval Loss: N/A, LR: 3.181818181818182e-05
{'loss': 0.5837, 'learning_rate': 3.181818181818182e-05, 'epoch': 21.25}
📊 [训练日志] Epoch: 21.88, Step: 175, Train Loss: N/A, Eval Loss: N/A, LR: 2.954545454545455e-05
{'loss': 0.6521, 'learning_rate': 2.954545454545455e-05, 'epoch': 21.88}
📊 [训练日志] Epoch: 22.50, Step: 180, Train Loss: N/A, Eval Loss: N/A, LR: 2.7272727272727273e-05
{'loss': 0.5671, 'learning_rate': 2.7272727272727273e-05, 'epoch': 22.5}
📊 [训练日志] Epoch: 23.12, Step: 185, Train Loss: N/A, Eval Loss: N/A, LR: 2.5e-05
{'loss': 0.6548, 'learning_rate': 2.5e-05, 'epoch': 23.12}
📊 [训练日志] Epoch: 23.75, Step: 190, Train Loss: N/A, Eval Loss: N/A, LR: 2.272727272727273e-05
{'loss': 0.5661, 'learning_rate': 2.272727272727273e-05, 'epoch': 23.75}
📊 [训练日志] Epoch: 24.38, Step: 195, Train Loss: N/A, Eval Loss: N/A, LR: 2.0454545454545457e-05
{'loss': 0.6504, 'learning_rate': 2.0454545454545457e-05, 'epoch': 24.38}
📊 [训练日志] Epoch: 25.00, Step: 200, Train Loss: N/A, Eval Loss: N/A, LR: 1.8181818181818182e-05
{'loss': 0.5835, 'learning_rate': 1.8181818181818182e-05, 'epoch': 25.0}

  0%|          | 0/12 [00:00<?, ?it/s][A
 17%|█▋        | 2/12 [00:00<00:04,  2.14it/s][A
 25%|██▌       | 3/12 [00:02<00:07,  1.16it/s][A
 33%|███▎      | 4/12 [00:03<00:08,  1.05s/it][A
 42%|████▏     | 5/12 [00:05<00:08,  1.18s/it][A
 50%|█████     | 6/12 [00:06<00:07,  1.25s/it][A
 58%|█████▊    | 7/12 [00:07<00:06,  1.22s/it][A
 67%|██████▋   | 8/12 [00:08<00:04,  1.19s/it][A
 75%|███████▌  | 9/12 [00:09<00:03,  1.11s/it][A
 83%|████████▎ | 10/12 [00:10<00:02,  1.02s/it][A
 92%|█████████▏| 11/12 [00:11<00:00,  1.09it/s][A
100%|██████████| 12/12 [00:12<00:00,  1.12it/s][A                                                   
                                               [A 83%|████████▎ | 200/240 [1:02:51<11:52, 17.81s/it]
100%|██████████| 12/12 [00:12<00:00,  1.12it/s][A
                                               [A/root/miniconda3/envs/DEALRec/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 84%|████████▍ | 201/240 [1:03:16<15:21, 23.64s/it] 84%|████████▍ | 202/240 [1:03:30<13:08, 20.74s/it] 85%|████████▍ | 203/240 [1:03:53<13:17, 21.54s/it] 85%|████████▌ | 204/240 [1:04:07<11:31, 19.21s/it] 85%|████████▌ | 205/240 [1:04:30<11:50, 20.30s/it]                                                    85%|████████▌ | 205/240 [1:04:30<11:50, 20.30s/it] 86%|████████▌ | 206/240 [1:04:44<10:25, 18.40s/it] 86%|████████▋ | 207/240 [1:05:06<10:50, 19.71s/it] 87%|████████▋ | 208/240 [1:05:20<09:32, 17.90s/it] 87%|████████▋ | 209/240 [1:05:44<10:10, 19.69s/it] 88%|████████▊ | 210/240 [1:05:58<08:58, 17.95s/it]                                                    88%|████████▊ | 210/240 [1:05:58<08:58, 17.95s/it] 88%|████████▊ | 211/240 [1:06:21<09:28, 19.59s/it] 88%|████████▊ | 212/240 [1:06:35<08:20, 17.88s/it] 89%|████████▉ | 213/240 [1:06:58<08:42, 19.37s/it] 89%|████████▉ | 214/240 [1:07:12<07:40, 17.71s/it] 90%|████████▉ | 215/240 [1:07:35<08:05, 19.41s/it]                                                    90%|████████▉ | 215/240 [1:07:35<08:05, 19.41s/it] 90%|█████████ | 216/240 [1:07:49<07:05, 17.73s/it] 90%|█████████ | 217/240 [1:08:12<07:25, 19.39s/it] 91%|█████████ | 218/240 [1:08:26<06:30, 17.75s/it] 91%|█████████▏| 219/240 [1:08:49<06:40, 19.09s/it] 92%|█████████▏| 220/240 [1:09:02<05:49, 17.47s/it]                                                    92%|█████████▏| 220/240 [1:09:02<05:49, 17.47s/it] 92%|█████████▏| 221/240 [1:09:27<06:12, 19.59s/it] 92%|█████████▎| 222/240 [1:09:41<05:22, 17.90s/it] 93%|█████████▎| 223/240 [1:10:04<05:30, 19.46s/it] 93%|█████████▎| 224/240 [1:10:18<04:45, 17.82s/it] 94%|█████████▍| 225/240 [1:10:40<04:49, 19.29s/it]                                                    94%|█████████▍| 225/240 [1:10:40<04:49, 19.29s/it] 94%|█████████▍| 226/240 [1:10:54<04:06, 17.61s/it] 95%|█████████▍| 227/240 [1:11:17<04:10, 19.28s/it] 95%|█████████▌| 228/240 [1:11:31<03:32, 17.69s/it] 95%|█████████▌| 229/240 [1:11:55<03:32, 19.35s/it] 96%|█████████▌| 230/240 [1:12:08<02:57, 17.70s/it]                                                    96%|█████████▌| 230/240 [1:12:08<02:57, 17.70s/it] 96%|█████████▋| 231/240 [1:12:33<02:56, 19.63s/it] 97%|█████████▋| 232/240 [1:12:46<02:23, 17.92s/it] 97%|█████████▋| 233/240 [1:13:10<02:16, 19.54s/it] 98%|█████████▊| 234/240 [1:13:24<01:47, 17.86s/it] 98%|█████████▊| 235/240 [1:13:47<01:38, 19.61s/it]                                                    98%|█████████▊| 235/240 [1:13:47<01:38, 19.61s/it] 98%|█████████▊| 236/240 [1:14:01<01:11, 17.87s/it] 99%|█████████▉| 237/240 [1:14:23<00:57, 19.16s/it] 99%|█████████▉| 238/240 [1:14:37<00:35, 17.53s/it]100%|█████████▉| 239/240 [1:15:01<00:19, 19.55s/it]100%|██████████| 240/240 [1:15:15<00:00, 17.89s/it]                                                   100%|██████████| 240/240 [1:15:15<00:00, 17.89s/it]                                                   100%|██████████| 240/240 [1:15:15<00:00, 17.89s/it]100%|██████████| 240/240 [1:15:15<00:00, 18.82s/it]
📊 [训练日志] Epoch: 25.00, Step: 200, Train Loss: N/A, Eval Loss: 0.8336045145988464, LR: N/A
{'eval_loss': 0.8336045145988464, 'eval_runtime': 12.8461, 'eval_samples_per_second': 14.946, 'eval_steps_per_second': 0.934, 'epoch': 25.0}
📊 [训练日志] Epoch: 25.62, Step: 205, Train Loss: N/A, Eval Loss: N/A, LR: 1.590909090909091e-05
{'loss': 0.6508, 'learning_rate': 1.590909090909091e-05, 'epoch': 25.62}
📊 [训练日志] Epoch: 26.25, Step: 210, Train Loss: N/A, Eval Loss: N/A, LR: 1.3636363636363637e-05
{'loss': 0.5727, 'learning_rate': 1.3636363636363637e-05, 'epoch': 26.25}
📊 [训练日志] Epoch: 26.88, Step: 215, Train Loss: N/A, Eval Loss: N/A, LR: 1.1363636363636365e-05
{'loss': 0.6418, 'learning_rate': 1.1363636363636365e-05, 'epoch': 26.88}
📊 [训练日志] Epoch: 27.50, Step: 220, Train Loss: N/A, Eval Loss: N/A, LR: 9.090909090909091e-06
{'loss': 0.5466, 'learning_rate': 9.090909090909091e-06, 'epoch': 27.5}
📊 [训练日志] Epoch: 28.12, Step: 225, Train Loss: N/A, Eval Loss: N/A, LR: 6.818181818181818e-06
{'loss': 0.6571, 'learning_rate': 6.818181818181818e-06, 'epoch': 28.12}
📊 [训练日志] Epoch: 28.75, Step: 230, Train Loss: N/A, Eval Loss: N/A, LR: 4.5454545454545455e-06
{'loss': 0.5779, 'learning_rate': 4.5454545454545455e-06, 'epoch': 28.75}
📊 [训练日志] Epoch: 29.38, Step: 235, Train Loss: N/A, Eval Loss: N/A, LR: 2.2727272727272728e-06
{'loss': 0.646, 'learning_rate': 2.2727272727272728e-06, 'epoch': 29.38}
📊 [训练日志] Epoch: 30.00, Step: 240, Train Loss: N/A, Eval Loss: N/A, LR: 0.0
{'loss': 0.5642, 'learning_rate': 0.0, 'epoch': 30.0}
📊 [训练日志] Epoch: 30.00, Step: 240, Train Loss: 0.8573504209518432, Eval Loss: N/A, LR: N/A
{'train_runtime': 4515.9628, 'train_samples_per_second': 6.803, 'train_steps_per_second': 0.053, 'train_loss': 0.8573504209518432, 'epoch': 30.0}

 If there's a warning about missing keys above, please disregard :)
