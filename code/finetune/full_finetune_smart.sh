#!/bin/bash

dataset=$1
fewshot=1024

echo "å¼€å§‹æ™ºèƒ½å¾®è°ƒæµç¨‹ï¼š${dataset} æ•°æ®é›† (å°è§„æ¨¡æµ‹è¯•ç‰ˆæœ¬)"
echo "åŒ…å«ï¼šæ£€æŸ¥å·²å­˜åœ¨æ¨¡å‹ -> å¾®è°ƒ/æ¢å¤ -> å°è§„æ¨¡æ¨ç† -> å°è§„æ¨¡è¯„ä¼°"

for seed in 2023
do
    for sample in 1024
    do  
        model_dir="./model/${dataset}/${seed}_${sample}"
        result_file="./results/${dataset}/${seed}_${sample}_small.json"
        
        echo "==== æ£€æŸ¥æ¨¡å‹çŠ¶æ€ ===="
        echo "æ¨¡å‹ç›®å½•: $model_dir"
        echo "ç»“æœæ–‡ä»¶: $result_file"
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
        if [ -f "$model_dir/adapter_model.bin" ]; then
            echo "âœ… å‘ç°å·²è®­ç»ƒçš„æ¨¡å‹ï¼"
            echo "ğŸ“ ä½ç½®: $model_dir"
            
            # æ£€æŸ¥æ¨ç†ç»“æœæ˜¯å¦å·²å­˜åœ¨
            if [ -f "$result_file" ]; then
                echo "âœ… æ¨ç†ç»“æœä¹Ÿå·²å­˜åœ¨ï¼Œè·³è¿‡æ•´ä¸ªæµç¨‹"
                echo "ğŸ“„ ç»“æœæ–‡ä»¶: $result_file"
                echo "å¦‚éœ€é‡æ–°è®­ç»ƒï¼Œè¯·åˆ é™¤æ¨¡å‹ç›®å½•: rm -rf $model_dir"
                continue
            else
                echo "âŒ æ¨ç†ç»“æœä¸å­˜åœ¨ï¼Œç›´æ¥è¿›è¡Œæ¨ç†"
                skip_training=true
            fi
        else
            echo "âŒ æœªå‘ç°å·²è®­ç»ƒæ¨¡å‹ï¼Œå¼€å§‹ä»å¤´è®­ç»ƒ"
            skip_training=false
        fi
        
        # æ ¹æ®æ£€æŸ¥ç»“æœå†³å®šæ˜¯å¦è®­ç»ƒ
        if [ "$skip_training" = false ]; then
            echo "==== å¼€å§‹å¾®è°ƒ ===="
            echo "éšæœºç§å­: $seed, æ ·æœ¬æ•°: $sample"
            
            # åˆ›å»ºæ—¥å¿—ç›®å½•
            log_dir="./logs/${dataset}/${seed}_${sample}"
            mkdir -p $log_dir
            
            # å¾®è°ƒè®­ç»ƒ - åŸºäºåŸå§‹ä½œè€…çš„å®Œæ•´é…ç½®
            # åŸå§‹: batch_size=128, micro_batch_size=16, num_epochs=50
            # 4090é€‚é…ç‰ˆæœ¬: é™ä½batch_sizeä½†ä¿æŒè®­ç»ƒå……åˆ†æ€§
            CUDA_VISIBLE_DEVICES=0 python finetune.py \
                --base_model /root/autodl-tmp/nku/DEALRec-main/models_cache/models--yahma--llama-7b-hf/snapshots/cf33055e5df9cc533abd7ea4707bf727ca2ada75 \
                --train_data_path ./data/${dataset}/train/train-${sample}.json \
                --val_data_path ./data/${dataset}/valid/valid-${sample}.json \
                --output_dir $model_dir \
                --batch_size 128 \
                --micro_batch_size 16 \
                --num_epochs 30 \
                --learning_rate 1e-4 \
                --cutoff_len 512 \
                --lora_r 8 \
                --lora_alpha 16 \
                --lora_dropout 0.05 \
                --lora_target_modules '[q_proj,v_proj,k_proj,o_proj]' \
                --train_on_inputs \
                --group_by_length \
                --seed $seed \
                --sample $sample \
                --log_file $log_dir/training_detailed.csv \
                2>&1 | tee $log_dir/training_console.log
            
            echo "==== å¾®è°ƒå®Œæˆ ===="
        else
            echo "==== è·³è¿‡è®­ç»ƒï¼Œä½¿ç”¨å·²å­˜åœ¨æ¨¡å‹ ===="
        fi
        
        echo "==== å¼€å§‹å°è§„æ¨¡æ¨ç† ===="
        
        # å°è§„æ¨¡æ¨ç† (ä½¿ç”¨inference_small.py)
        CUDA_VISIBLE_DEVICES=0 python inference_small.py \
            --base_model /root/autodl-tmp/nku/DEALRec-main/models_cache/models--yahma--llama-7b-hf/snapshots/cf33055e5df9cc533abd7ea4707bf727ca2ada75 \
            --lora_weights $model_dir \
            --result_json_data $result_file \
            --dataset ${dataset}

        echo "==== æ¨ç†å®Œæˆï¼Œå¼€å§‹å°è§„æ¨¡è¯„ä¼° ===="
        
        # å°è§„æ¨¡è¯„ä¼° (åªä¼ é€’æ”¯æŒçš„å‚æ•°)
        echo "å½“å‰å·¥ä½œç›®å½•: $(pwd)"
        CUDA_VISIBLE_DEVICES=0 python evaluate_small.py \
            --result_file $result_file \
            --dataset ${dataset} \
            --batch_size 4
        
        echo "==== å®Œæ•´æµç¨‹å®Œæˆï¼===="
        echo "æ¨¡å‹ä¿å­˜ä½ç½®: $model_dir"
        echo "ç»“æœä¿å­˜ä½ç½®: $result_file"
        echo "=========================================="
    done
done

echo "ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼(å°è§„æ¨¡æµ‹è¯•ç‰ˆæœ¬)" 